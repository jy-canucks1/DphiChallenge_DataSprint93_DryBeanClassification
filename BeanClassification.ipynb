{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "L52b4HTJwhzQ"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "from decimal import Decimal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Uploade files\n",
        "uploaded=files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "JLL4OJZUwjkG",
        "outputId": "f5e955fd-2686-4283-98b0-9ef70595dcfd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c5263d2c-3aa8-4cae-a0a1-dc2d68d91aaa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c5263d2c-3aa8-4cae-a0a1-dc2d68d91aaa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test_dataset.csv to test_dataset.csv\n",
            "Saving train_dataset.csv to train_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Get the number of rows in .csv file\n",
        "def len_data(filename):\n",
        "  i=0\n",
        "  with open(filename) as training_file:\n",
        "        csv_reader = csv.reader(training_file, delimiter=',')\n",
        "        first_line = True\n",
        "        temp_images = []\n",
        "        temp_labels = []\n",
        "        for row in csv_reader:\n",
        "            if first_line:\n",
        "                # print(\"Ignoring first line\")\n",
        "                first_line = False\n",
        "            else:\n",
        "              i+=1\n",
        "  return i"
      ],
      "metadata": {
        "id": "1-E7vWuk0Xk_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Get the numpy tensor of the data for training\n",
        "def get_train_data(filename):\n",
        "    with open(filename) as training_file:\n",
        "        csv_reader = csv.reader(training_file, delimiter=',')\n",
        "        temp_data = []\n",
        "        temp_labels = []\n",
        "        j = 0\n",
        "        for row in csv_reader:\n",
        "            if row[0]==\"Area\":\n",
        "              row = False   \n",
        "            else:\n",
        "              ## Manipulate data to spread properly\n",
        "              row[4] = str((Decimal(row[4]) - 1) * 1000)\n",
        "              row[5] = str((Decimal(row[5])-Decimal(0.75)) * 10000)\n",
        "              row[8] = str((Decimal(row[8])-Decimal(0.7)) * 10000)\n",
        "              row[9] = str((1-Decimal(row[9])) * 100000)\n",
        "              row[10] = str((Decimal(row[10])-Decimal(0.8)) * 1000)\n",
        "              row[11] = str((Decimal(row[11])-Decimal(0.77)) * 1000)\n",
        "              row[12] = str(Decimal(row[12]) * 100000)\n",
        "              row[13] = str(Decimal(row[13]) * 100000)\n",
        "              row[14] = str(Decimal(row[14]) * 1000)\n",
        "              row[15] = str((1-Decimal(row[15])) * 1000000)\n",
        "\n",
        "              ## Get data from a single row and add the data to the list\n",
        "              bean_data = row[0:16]\n",
        "              temp_data.append(bean_data)\n",
        "\n",
        "              ## Get labels corresponding to each class\n",
        "              if row[16]==\"CALI\":\n",
        "                temp_labels.append(\"0\")\n",
        "              elif row[16]==\"SIRA\":\n",
        "                temp_labels.append(\"1\")\n",
        "              elif row[16]==\"HOROZ\":\n",
        "                temp_labels.append(\"2\")\n",
        "              elif row[16]==\"BARBUNYA\":\n",
        "                temp_labels.append(\"3\")\n",
        "              elif row[16]==\"DERMASON\":\n",
        "               temp_labels.append(\"4\")\n",
        "              elif row[16]==\"SEKER\":\n",
        "                temp_labels.append(\"5\")\n",
        "              else: \n",
        "                temp_labels.append(\"6\")\n",
        "\n",
        "        ## Convert the list to numpy array with float type\n",
        "        train_data = np.array(temp_data).astype('float')\n",
        "        train_labels = np.array(temp_labels).astype('float')\n",
        "        \n",
        "\n",
        "    return  train_data, train_labels\n",
        "## Get the numpy tensor from actual data to train\n",
        "training_data, training_labels = get_train_data('train_dataset.csv')\n",
        "\n",
        "## Check the shape of dataset tensor and label type\n",
        "print(training_data.shape)\n",
        "print(training_data)\n",
        "print(training_labels)\n",
        "print(training_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyuZRr-hwlGe",
        "outputId": "ef09fdb3-816c-44f0-f232-fb09a01a9b6b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2500, 16)\n",
            "[[69892.          1052.973        389.85577069 ...   117.95478599\n",
            "    585.50371191  1790.62531492]\n",
            " [34584.           704.813        272.44836338 ...   171.01043524\n",
            "    593.22157057  2160.72048222]\n",
            " [72102.          1072.061        377.61673029 ...   133.90402427\n",
            "    643.80593402  1609.76613481]\n",
            " ...\n",
            " [81774.          1082.182        400.88468802 ...   126.92782451\n",
            "    647.86784206  6839.36784107]\n",
            " [41619.           741.44         261.1093812  ...   233.78907594\n",
            "    777.24298062  1611.13566517]\n",
            " [50043.           894.418        357.31904411 ...   109.69197261\n",
            "    499.04663173  8799.16506752]]\n",
            "[3. 4. 3. ... 0. 5. 2.]\n",
            "(2500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Split the data for training into data for training and data for validation\n",
        "leng = len_data('train_dataset.csv') -1\n",
        "data_val = training_data[int(leng *.92):]\n",
        "data_trained = training_data[:int(leng *.92)]\n",
        "\n",
        "label_val = training_labels[int(leng *.92):]\n",
        "label_trained = training_labels[:int(leng *.92)]\n",
        "\n",
        "## Convert the dataset list to a numpy tensor\n",
        "data_val = np.expand_dims(data_val, axis=2)\n",
        "data_trained = np.expand_dims(data_trained, axis=2)"
      ],
      "metadata": {
        "id": "v9i8O_5TSVMT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Build the model using Keras\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='softplus', input_shape=(16,)),\n",
        "    tf.keras.layers.Dense(64, activation='softplus'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(7, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "## Fitting model\n",
        "history = model.fit(data_trained, label_trained, epochs=500, validation_data=(data_val, label_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fau90g65ZuI2",
        "outputId": "35a74df1-f05a-45b0-a238-9c0cd0a302a6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 516.5917 - accuracy: 0.2218 - val_loss: 72.4237 - val_accuracy: 0.3582\n",
            "Epoch 2/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 77.3191 - accuracy: 0.3954 - val_loss: 41.7503 - val_accuracy: 0.4378\n",
            "Epoch 3/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 39.9212 - accuracy: 0.5220 - val_loss: 24.1863 - val_accuracy: 0.6269\n",
            "Epoch 4/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 31.0322 - accuracy: 0.5855 - val_loss: 15.7636 - val_accuracy: 0.7015\n",
            "Epoch 5/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 18.9446 - accuracy: 0.6642 - val_loss: 15.7712 - val_accuracy: 0.7114\n",
            "Epoch 6/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 22.0800 - accuracy: 0.6520 - val_loss: 22.9572 - val_accuracy: 0.6667\n",
            "Epoch 7/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 18.1511 - accuracy: 0.6877 - val_loss: 24.3819 - val_accuracy: 0.6617\n",
            "Epoch 8/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 27.3637 - accuracy: 0.6681 - val_loss: 19.2572 - val_accuracy: 0.6269\n",
            "Epoch 9/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 16.1110 - accuracy: 0.7216 - val_loss: 12.2598 - val_accuracy: 0.7463\n",
            "Epoch 10/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 17.6653 - accuracy: 0.7177 - val_loss: 33.3855 - val_accuracy: 0.6866\n",
            "Epoch 11/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 16.1478 - accuracy: 0.7325 - val_loss: 8.7299 - val_accuracy: 0.8408\n",
            "Epoch 12/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 20.4600 - accuracy: 0.7077 - val_loss: 24.5351 - val_accuracy: 0.6517\n",
            "Epoch 13/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 18.8394 - accuracy: 0.7321 - val_loss: 30.1484 - val_accuracy: 0.5721\n",
            "Epoch 14/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 20.5231 - accuracy: 0.7308 - val_loss: 14.1012 - val_accuracy: 0.7363\n",
            "Epoch 15/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 12.3023 - accuracy: 0.7877 - val_loss: 37.0491 - val_accuracy: 0.5821\n",
            "Epoch 16/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 16.7371 - accuracy: 0.7695 - val_loss: 7.1411 - val_accuracy: 0.8607\n",
            "Epoch 17/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 15.4539 - accuracy: 0.7682 - val_loss: 29.3215 - val_accuracy: 0.7214\n",
            "Epoch 18/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 9.8374 - accuracy: 0.8260 - val_loss: 8.2751 - val_accuracy: 0.8458\n",
            "Epoch 19/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 9.5507 - accuracy: 0.8177 - val_loss: 9.6959 - val_accuracy: 0.8507\n",
            "Epoch 20/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 9.8641 - accuracy: 0.8351 - val_loss: 10.4596 - val_accuracy: 0.8308\n",
            "Epoch 21/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 7.8146 - accuracy: 0.8482 - val_loss: 15.0262 - val_accuracy: 0.7065\n",
            "Epoch 22/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 15.3799 - accuracy: 0.7829 - val_loss: 13.0602 - val_accuracy: 0.7562\n",
            "Epoch 23/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 11.0207 - accuracy: 0.8117 - val_loss: 11.9351 - val_accuracy: 0.8109\n",
            "Epoch 24/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 12.9874 - accuracy: 0.7956 - val_loss: 8.0632 - val_accuracy: 0.8657\n",
            "Epoch 25/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 15.2086 - accuracy: 0.7986 - val_loss: 12.3857 - val_accuracy: 0.8507\n",
            "Epoch 26/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 7.2296 - accuracy: 0.8643 - val_loss: 7.2038 - val_accuracy: 0.8806\n",
            "Epoch 27/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 24.9835 - accuracy: 0.7468 - val_loss: 33.7656 - val_accuracy: 0.6766\n",
            "Epoch 28/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 10.9515 - accuracy: 0.8117 - val_loss: 10.8020 - val_accuracy: 0.7811\n",
            "Epoch 29/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 13.5309 - accuracy: 0.7903 - val_loss: 13.0082 - val_accuracy: 0.8060\n",
            "Epoch 30/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 7.9746 - accuracy: 0.8408 - val_loss: 12.9796 - val_accuracy: 0.7811\n",
            "Epoch 31/500\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 8.3546 - accuracy: 0.8412 - val_loss: 11.2545 - val_accuracy: 0.8159\n",
            "Epoch 32/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 7.7924 - accuracy: 0.8565 - val_loss: 8.2403 - val_accuracy: 0.8308\n",
            "Epoch 33/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 16.3213 - accuracy: 0.7886 - val_loss: 9.9997 - val_accuracy: 0.8209\n",
            "Epoch 34/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 13.2409 - accuracy: 0.8086 - val_loss: 14.7298 - val_accuracy: 0.7861\n",
            "Epoch 35/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 12.4317 - accuracy: 0.8073 - val_loss: 10.2216 - val_accuracy: 0.8209\n",
            "Epoch 36/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 10.8784 - accuracy: 0.8264 - val_loss: 15.4489 - val_accuracy: 0.7612\n",
            "Epoch 37/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 21.5853 - accuracy: 0.7516 - val_loss: 7.8757 - val_accuracy: 0.8657\n",
            "Epoch 38/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 5.9109 - accuracy: 0.8804 - val_loss: 6.8311 - val_accuracy: 0.8657\n",
            "Epoch 39/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 7.5905 - accuracy: 0.8473 - val_loss: 6.7806 - val_accuracy: 0.8806\n",
            "Epoch 40/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 9.8173 - accuracy: 0.8182 - val_loss: 14.8737 - val_accuracy: 0.7761\n",
            "Epoch 41/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 8.0118 - accuracy: 0.8452 - val_loss: 14.5588 - val_accuracy: 0.7463\n",
            "Epoch 42/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 7.0841 - accuracy: 0.8669 - val_loss: 9.5784 - val_accuracy: 0.8209\n",
            "Epoch 43/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 5.5776 - accuracy: 0.8691 - val_loss: 4.4060 - val_accuracy: 0.8955\n",
            "Epoch 44/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 6.0466 - accuracy: 0.8625 - val_loss: 9.5827 - val_accuracy: 0.8109\n",
            "Epoch 45/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 7.1915 - accuracy: 0.8560 - val_loss: 11.5896 - val_accuracy: 0.8060\n",
            "Epoch 46/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 5.4140 - accuracy: 0.8791 - val_loss: 6.9151 - val_accuracy: 0.8408\n",
            "Epoch 47/500\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 5.0696 - accuracy: 0.8747 - val_loss: 7.2735 - val_accuracy: 0.8308\n",
            "Epoch 48/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 4.7288 - accuracy: 0.8765 - val_loss: 9.6193 - val_accuracy: 0.7612\n",
            "Epoch 49/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 5.5602 - accuracy: 0.8586 - val_loss: 6.7209 - val_accuracy: 0.8259\n",
            "Epoch 50/500\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 15.8712 - accuracy: 0.7716 - val_loss: 10.1636 - val_accuracy: 0.8159\n",
            "Epoch 51/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 7.0009 - accuracy: 0.8404 - val_loss: 4.1421 - val_accuracy: 0.8706\n",
            "Epoch 52/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 6.4851 - accuracy: 0.8452 - val_loss: 8.3833 - val_accuracy: 0.8209\n",
            "Epoch 53/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 4.7978 - accuracy: 0.8682 - val_loss: 9.0465 - val_accuracy: 0.7910\n",
            "Epoch 54/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 5.7987 - accuracy: 0.8478 - val_loss: 4.5089 - val_accuracy: 0.8607\n",
            "Epoch 55/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 4.3417 - accuracy: 0.8708 - val_loss: 6.1577 - val_accuracy: 0.8657\n",
            "Epoch 56/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 3.6006 - accuracy: 0.8852 - val_loss: 3.4609 - val_accuracy: 0.8657\n",
            "Epoch 57/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 3.1544 - accuracy: 0.8856 - val_loss: 3.5525 - val_accuracy: 0.8856\n",
            "Epoch 58/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 3.9456 - accuracy: 0.8712 - val_loss: 4.9485 - val_accuracy: 0.8408\n",
            "Epoch 59/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.8499 - accuracy: 0.8813 - val_loss: 3.3343 - val_accuracy: 0.8408\n",
            "Epoch 60/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 3.7617 - accuracy: 0.8717 - val_loss: 3.5289 - val_accuracy: 0.8905\n",
            "Epoch 61/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 4.3791 - accuracy: 0.8508 - val_loss: 4.3060 - val_accuracy: 0.8557\n",
            "Epoch 62/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 3.8245 - accuracy: 0.8543 - val_loss: 3.0699 - val_accuracy: 0.8856\n",
            "Epoch 63/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 3.2456 - accuracy: 0.8717 - val_loss: 2.0960 - val_accuracy: 0.9005\n",
            "Epoch 64/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 3.1110 - accuracy: 0.8704 - val_loss: 4.8792 - val_accuracy: 0.8209\n",
            "Epoch 65/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 3.4957 - accuracy: 0.8639 - val_loss: 6.1618 - val_accuracy: 0.7861\n",
            "Epoch 66/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 5.5790 - accuracy: 0.8182 - val_loss: 5.4822 - val_accuracy: 0.8060\n",
            "Epoch 67/500\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 3.0664 - accuracy: 0.8756 - val_loss: 2.5011 - val_accuracy: 0.8657\n",
            "Epoch 68/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 3.9963 - accuracy: 0.8360 - val_loss: 1.9926 - val_accuracy: 0.9055\n",
            "Epoch 69/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 3.9063 - accuracy: 0.8612 - val_loss: 2.8463 - val_accuracy: 0.8159\n",
            "Epoch 70/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.6576 - accuracy: 0.8734 - val_loss: 3.6262 - val_accuracy: 0.8507\n",
            "Epoch 71/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.8285 - accuracy: 0.8756 - val_loss: 2.1801 - val_accuracy: 0.8657\n",
            "Epoch 72/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 3.0493 - accuracy: 0.8634 - val_loss: 2.0609 - val_accuracy: 0.8756\n",
            "Epoch 73/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 3.6936 - accuracy: 0.8486 - val_loss: 4.1540 - val_accuracy: 0.8010\n",
            "Epoch 74/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.8901 - accuracy: 0.8678 - val_loss: 1.7788 - val_accuracy: 0.8557\n",
            "Epoch 75/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.3386 - accuracy: 0.8856 - val_loss: 2.1777 - val_accuracy: 0.8905\n",
            "Epoch 76/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.2726 - accuracy: 0.8826 - val_loss: 2.5194 - val_accuracy: 0.8408\n",
            "Epoch 77/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.5017 - accuracy: 0.8652 - val_loss: 3.5947 - val_accuracy: 0.8209\n",
            "Epoch 78/500\n",
            "72/72 [==============================] - 0s 1ms/step - loss: 2.7081 - accuracy: 0.8639 - val_loss: 2.4840 - val_accuracy: 0.8905\n",
            "Epoch 79/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 3.2556 - accuracy: 0.8434 - val_loss: 2.6381 - val_accuracy: 0.8756\n",
            "Epoch 80/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 5.1818 - accuracy: 0.8304 - val_loss: 16.0202 - val_accuracy: 0.7015\n",
            "Epoch 81/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 4.2064 - accuracy: 0.8243 - val_loss: 3.9667 - val_accuracy: 0.8060\n",
            "Epoch 82/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.2452 - accuracy: 0.8778 - val_loss: 3.2730 - val_accuracy: 0.8408\n",
            "Epoch 83/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.7795 - accuracy: 0.8856 - val_loss: 1.7311 - val_accuracy: 0.8856\n",
            "Epoch 84/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.6512 - accuracy: 0.8565 - val_loss: 9.4221 - val_accuracy: 0.6070\n",
            "Epoch 85/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 3.0044 - accuracy: 0.8465 - val_loss: 2.5913 - val_accuracy: 0.8408\n",
            "Epoch 86/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.1489 - accuracy: 0.8799 - val_loss: 2.6519 - val_accuracy: 0.8557\n",
            "Epoch 87/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.0657 - accuracy: 0.8734 - val_loss: 2.1608 - val_accuracy: 0.8557\n",
            "Epoch 88/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.6760 - accuracy: 0.8469 - val_loss: 2.2408 - val_accuracy: 0.8756\n",
            "Epoch 89/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.8472 - accuracy: 0.8834 - val_loss: 1.9558 - val_accuracy: 0.8706\n",
            "Epoch 90/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.1784 - accuracy: 0.8617 - val_loss: 1.9250 - val_accuracy: 0.8607\n",
            "Epoch 91/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.8719 - accuracy: 0.8351 - val_loss: 3.7197 - val_accuracy: 0.7761\n",
            "Epoch 92/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.9501 - accuracy: 0.8799 - val_loss: 2.3872 - val_accuracy: 0.8358\n",
            "Epoch 93/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.6582 - accuracy: 0.8769 - val_loss: 2.4353 - val_accuracy: 0.8308\n",
            "Epoch 94/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.1198 - accuracy: 0.8582 - val_loss: 3.5975 - val_accuracy: 0.7761\n",
            "Epoch 95/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.2252 - accuracy: 0.8569 - val_loss: 2.0780 - val_accuracy: 0.8657\n",
            "Epoch 96/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.7520 - accuracy: 0.8786 - val_loss: 2.6561 - val_accuracy: 0.8159\n",
            "Epoch 97/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.1485 - accuracy: 0.8569 - val_loss: 2.3441 - val_accuracy: 0.8458\n",
            "Epoch 98/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.4545 - accuracy: 0.8478 - val_loss: 1.9928 - val_accuracy: 0.8557\n",
            "Epoch 99/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.2102 - accuracy: 0.8499 - val_loss: 2.6789 - val_accuracy: 0.7811\n",
            "Epoch 100/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.6896 - accuracy: 0.8639 - val_loss: 3.4425 - val_accuracy: 0.7413\n",
            "Epoch 101/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.0889 - accuracy: 0.8547 - val_loss: 2.7742 - val_accuracy: 0.7910\n",
            "Epoch 102/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.5415 - accuracy: 0.8752 - val_loss: 2.2956 - val_accuracy: 0.8209\n",
            "Epoch 103/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.3269 - accuracy: 0.8808 - val_loss: 1.5527 - val_accuracy: 0.8458\n",
            "Epoch 104/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.4426 - accuracy: 0.8565 - val_loss: 1.5778 - val_accuracy: 0.8607\n",
            "Epoch 105/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.2962 - accuracy: 0.8652 - val_loss: 1.1659 - val_accuracy: 0.8607\n",
            "Epoch 106/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.5973 - accuracy: 0.8652 - val_loss: 1.9110 - val_accuracy: 0.8657\n",
            "Epoch 107/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.1937 - accuracy: 0.8543 - val_loss: 22.2453 - val_accuracy: 0.6169\n",
            "Epoch 108/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 4.9975 - accuracy: 0.7864 - val_loss: 1.4292 - val_accuracy: 0.8657\n",
            "Epoch 109/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.3401 - accuracy: 0.8808 - val_loss: 1.0879 - val_accuracy: 0.8507\n",
            "Epoch 110/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.9998 - accuracy: 0.8834 - val_loss: 1.7234 - val_accuracy: 0.8557\n",
            "Epoch 111/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.1988 - accuracy: 0.8839 - val_loss: 0.7008 - val_accuracy: 0.8806\n",
            "Epoch 112/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.9836 - accuracy: 0.8752 - val_loss: 1.3458 - val_accuracy: 0.8806\n",
            "Epoch 113/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.8684 - accuracy: 0.8930 - val_loss: 0.6806 - val_accuracy: 0.8756\n",
            "Epoch 114/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.0163 - accuracy: 0.8865 - val_loss: 0.7768 - val_accuracy: 0.8856\n",
            "Epoch 115/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.1900 - accuracy: 0.8538 - val_loss: 0.9944 - val_accuracy: 0.8706\n",
            "Epoch 116/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.2308 - accuracy: 0.8734 - val_loss: 2.4568 - val_accuracy: 0.7861\n",
            "Epoch 117/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.5947 - accuracy: 0.8517 - val_loss: 1.1170 - val_accuracy: 0.8856\n",
            "Epoch 118/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.0781 - accuracy: 0.8791 - val_loss: 0.7791 - val_accuracy: 0.8806\n",
            "Epoch 119/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.0775 - accuracy: 0.8782 - val_loss: 1.4783 - val_accuracy: 0.8408\n",
            "Epoch 120/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.2328 - accuracy: 0.8565 - val_loss: 1.1326 - val_accuracy: 0.8458\n",
            "Epoch 121/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.3274 - accuracy: 0.8538 - val_loss: 0.6566 - val_accuracy: 0.8955\n",
            "Epoch 122/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.3801 - accuracy: 0.8508 - val_loss: 0.8428 - val_accuracy: 0.8806\n",
            "Epoch 123/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.5231 - accuracy: 0.8573 - val_loss: 1.8261 - val_accuracy: 0.8458\n",
            "Epoch 124/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.3078 - accuracy: 0.8504 - val_loss: 0.7538 - val_accuracy: 0.8856\n",
            "Epoch 125/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.7541 - accuracy: 0.8734 - val_loss: 0.6479 - val_accuracy: 0.8756\n",
            "Epoch 126/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.9862 - accuracy: 0.8656 - val_loss: 0.8719 - val_accuracy: 0.8557\n",
            "Epoch 127/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.7227 - accuracy: 0.8934 - val_loss: 1.0277 - val_accuracy: 0.8259\n",
            "Epoch 128/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.7658 - accuracy: 0.8817 - val_loss: 0.7205 - val_accuracy: 0.8706\n",
            "Epoch 129/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6672 - accuracy: 0.8821 - val_loss: 0.7710 - val_accuracy: 0.8358\n",
            "Epoch 130/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.9775 - accuracy: 0.8482 - val_loss: 0.8469 - val_accuracy: 0.8756\n",
            "Epoch 131/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.0908 - accuracy: 0.8482 - val_loss: 1.1638 - val_accuracy: 0.8458\n",
            "Epoch 132/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.9749 - accuracy: 0.8547 - val_loss: 1.1670 - val_accuracy: 0.8358\n",
            "Epoch 133/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.0415 - accuracy: 0.8077 - val_loss: 1.3418 - val_accuracy: 0.8259\n",
            "Epoch 134/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.9773 - accuracy: 0.7856 - val_loss: 1.8630 - val_accuracy: 0.8060\n",
            "Epoch 135/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.4051 - accuracy: 0.8382 - val_loss: 0.8695 - val_accuracy: 0.8657\n",
            "Epoch 136/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.0029 - accuracy: 0.8734 - val_loss: 0.6328 - val_accuracy: 0.8806\n",
            "Epoch 137/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.8947 - val_loss: 0.6286 - val_accuracy: 0.8607\n",
            "Epoch 138/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.8891 - val_loss: 0.5931 - val_accuracy: 0.8856\n",
            "Epoch 139/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.8743 - val_loss: 0.6434 - val_accuracy: 0.8756\n",
            "Epoch 140/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.8852 - val_loss: 0.4025 - val_accuracy: 0.8955\n",
            "Epoch 141/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.8878 - val_loss: 0.6027 - val_accuracy: 0.8657\n",
            "Epoch 142/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.8978 - val_loss: 0.3790 - val_accuracy: 0.8856\n",
            "Epoch 143/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.8808 - val_loss: 0.6451 - val_accuracy: 0.8856\n",
            "Epoch 144/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8886 - val_loss: 0.4049 - val_accuracy: 0.8756\n",
            "Epoch 145/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.8952 - val_loss: 0.7587 - val_accuracy: 0.8408\n",
            "Epoch 146/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.8795 - val_loss: 0.6341 - val_accuracy: 0.8607\n",
            "Epoch 147/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.0811 - accuracy: 0.8138 - val_loss: 1.0050 - val_accuracy: 0.7960\n",
            "Epoch 148/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.7181 - accuracy: 0.8739 - val_loss: 0.8429 - val_accuracy: 0.8607\n",
            "Epoch 149/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.8882 - val_loss: 0.5201 - val_accuracy: 0.8657\n",
            "Epoch 150/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.5559 - accuracy: 0.7990 - val_loss: 1.3668 - val_accuracy: 0.8308\n",
            "Epoch 151/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.9933 - accuracy: 0.8499 - val_loss: 0.8234 - val_accuracy: 0.8358\n",
            "Epoch 152/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.8506 - accuracy: 0.8673 - val_loss: 0.8662 - val_accuracy: 0.8308\n",
            "Epoch 153/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8987 - val_loss: 0.5155 - val_accuracy: 0.8706\n",
            "Epoch 154/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8886 - val_loss: 0.5536 - val_accuracy: 0.8905\n",
            "Epoch 155/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8900 - val_loss: 0.4838 - val_accuracy: 0.8756\n",
            "Epoch 156/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3587 - accuracy: 0.9082 - val_loss: 0.3722 - val_accuracy: 0.9055\n",
            "Epoch 157/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.3875 - accuracy: 0.7547 - val_loss: 0.8825 - val_accuracy: 0.8358\n",
            "Epoch 158/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.8164 - accuracy: 0.8438 - val_loss: 1.1105 - val_accuracy: 0.8010\n",
            "Epoch 159/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.8872 - accuracy: 0.8560 - val_loss: 0.5080 - val_accuracy: 0.8905\n",
            "Epoch 160/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 2.1893 - accuracy: 0.7621 - val_loss: 1.2123 - val_accuracy: 0.8507\n",
            "Epoch 161/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.8353 - accuracy: 0.8530 - val_loss: 0.4330 - val_accuracy: 0.8806\n",
            "Epoch 162/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.8843 - val_loss: 0.3453 - val_accuracy: 0.8806\n",
            "Epoch 163/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.9034 - val_loss: 0.4114 - val_accuracy: 0.8706\n",
            "Epoch 164/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8904 - val_loss: 0.3499 - val_accuracy: 0.8806\n",
            "Epoch 165/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8847 - val_loss: 0.7821 - val_accuracy: 0.7861\n",
            "Epoch 166/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.8425 - val_loss: 0.4092 - val_accuracy: 0.8706\n",
            "Epoch 167/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.8582 - val_loss: 0.4978 - val_accuracy: 0.8408\n",
            "Epoch 168/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.8813 - val_loss: 0.6056 - val_accuracy: 0.8458\n",
            "Epoch 169/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.8469 - val_loss: 0.5116 - val_accuracy: 0.8458\n",
            "Epoch 170/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.7124 - accuracy: 0.8243 - val_loss: 0.6804 - val_accuracy: 0.7512\n",
            "Epoch 171/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.0745 - accuracy: 0.7764 - val_loss: 1.0582 - val_accuracy: 0.7662\n",
            "Epoch 172/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.8604 - val_loss: 0.5563 - val_accuracy: 0.8408\n",
            "Epoch 173/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.8556 - val_loss: 0.6634 - val_accuracy: 0.7960\n",
            "Epoch 174/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.8538 - val_loss: 0.7172 - val_accuracy: 0.8060\n",
            "Epoch 175/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.4080 - accuracy: 0.7795 - val_loss: 0.4586 - val_accuracy: 0.8706\n",
            "Epoch 176/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.8643 - val_loss: 0.7231 - val_accuracy: 0.8308\n",
            "Epoch 177/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.8399 - val_loss: 0.4058 - val_accuracy: 0.8706\n",
            "Epoch 178/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8778 - val_loss: 0.3294 - val_accuracy: 0.8806\n",
            "Epoch 179/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8739 - val_loss: 0.3839 - val_accuracy: 0.8607\n",
            "Epoch 180/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8817 - val_loss: 0.2805 - val_accuracy: 0.8955\n",
            "Epoch 181/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8708 - val_loss: 0.6276 - val_accuracy: 0.8109\n",
            "Epoch 182/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3660 - accuracy: 0.8778 - val_loss: 0.3460 - val_accuracy: 0.8706\n",
            "Epoch 183/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8852 - val_loss: 0.6595 - val_accuracy: 0.8408\n",
            "Epoch 184/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.8673 - val_loss: 0.3199 - val_accuracy: 0.8756\n",
            "Epoch 185/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8956 - val_loss: 0.3571 - val_accuracy: 0.8756\n",
            "Epoch 186/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.8808 - val_loss: 0.4777 - val_accuracy: 0.8856\n",
            "Epoch 187/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.8547 - val_loss: 0.5073 - val_accuracy: 0.8458\n",
            "Epoch 188/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8913 - val_loss: 0.3549 - val_accuracy: 0.8905\n",
            "Epoch 189/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.5594 - accuracy: 0.8482 - val_loss: 0.6234 - val_accuracy: 0.6716\n",
            "Epoch 190/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.8421 - val_loss: 0.6171 - val_accuracy: 0.8159\n",
            "Epoch 191/500\n",
            "72/72 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8821 - val_loss: 0.4557 - val_accuracy: 0.8209\n",
            "Epoch 192/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8721 - val_loss: 0.4130 - val_accuracy: 0.8458\n",
            "Epoch 193/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8860 - val_loss: 0.4378 - val_accuracy: 0.8458\n",
            "Epoch 194/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8652 - val_loss: 0.6995 - val_accuracy: 0.7960\n",
            "Epoch 195/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8721 - val_loss: 0.3148 - val_accuracy: 0.8905\n",
            "Epoch 196/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8556 - val_loss: 0.4351 - val_accuracy: 0.8607\n",
            "Epoch 197/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.8612 - val_loss: 0.5395 - val_accuracy: 0.8308\n",
            "Epoch 198/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3727 - accuracy: 0.8782 - val_loss: 0.6258 - val_accuracy: 0.8557\n",
            "Epoch 199/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8778 - val_loss: 0.5138 - val_accuracy: 0.8408\n",
            "Epoch 200/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.8671 - accuracy: 0.8117 - val_loss: 1.9080 - val_accuracy: 0.6866\n",
            "Epoch 201/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 1.0062 - accuracy: 0.7729 - val_loss: 0.4898 - val_accuracy: 0.8507\n",
            "Epoch 202/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.8756 - val_loss: 0.3422 - val_accuracy: 0.8856\n",
            "Epoch 203/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8682 - val_loss: 0.2977 - val_accuracy: 0.8905\n",
            "Epoch 204/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8873 - val_loss: 0.3121 - val_accuracy: 0.8856\n",
            "Epoch 205/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3470 - accuracy: 0.8804 - val_loss: 0.3968 - val_accuracy: 0.8607\n",
            "Epoch 206/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8786 - val_loss: 0.4782 - val_accuracy: 0.8259\n",
            "Epoch 207/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.8547 - val_loss: 0.3313 - val_accuracy: 0.8806\n",
            "Epoch 208/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8791 - val_loss: 0.3752 - val_accuracy: 0.8806\n",
            "Epoch 209/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.8565 - val_loss: 0.7190 - val_accuracy: 0.7910\n",
            "Epoch 210/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.8412 - val_loss: 0.4274 - val_accuracy: 0.8408\n",
            "Epoch 211/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8813 - val_loss: 0.8500 - val_accuracy: 0.7612\n",
            "Epoch 212/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8734 - val_loss: 0.4517 - val_accuracy: 0.8607\n",
            "Epoch 213/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8791 - val_loss: 0.4076 - val_accuracy: 0.8607\n",
            "Epoch 214/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8926 - val_loss: 0.4127 - val_accuracy: 0.8408\n",
            "Epoch 215/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3686 - accuracy: 0.8791 - val_loss: 0.4632 - val_accuracy: 0.8358\n",
            "Epoch 216/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.8517 - val_loss: 1.3113 - val_accuracy: 0.8159\n",
            "Epoch 217/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8743 - val_loss: 0.4841 - val_accuracy: 0.8557\n",
            "Epoch 218/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.8304 - val_loss: 1.0533 - val_accuracy: 0.7413\n",
            "Epoch 219/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.8260 - val_loss: 0.7127 - val_accuracy: 0.8010\n",
            "Epoch 220/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.8678 - val_loss: 0.6911 - val_accuracy: 0.8657\n",
            "Epoch 221/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8604 - val_loss: 0.4317 - val_accuracy: 0.8657\n",
            "Epoch 222/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8660 - val_loss: 1.4911 - val_accuracy: 0.8607\n",
            "Epoch 223/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.7186 - accuracy: 0.8217 - val_loss: 0.4374 - val_accuracy: 0.8657\n",
            "Epoch 224/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8717 - val_loss: 0.3389 - val_accuracy: 0.8856\n",
            "Epoch 225/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8578 - val_loss: 0.4354 - val_accuracy: 0.8458\n",
            "Epoch 226/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8869 - val_loss: 0.3268 - val_accuracy: 0.8905\n",
            "Epoch 227/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8634 - val_loss: 0.3177 - val_accuracy: 0.8657\n",
            "Epoch 228/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8799 - val_loss: 0.3709 - val_accuracy: 0.8657\n",
            "Epoch 229/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.8330 - val_loss: 0.3300 - val_accuracy: 0.8955\n",
            "Epoch 230/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8634 - val_loss: 0.5239 - val_accuracy: 0.8109\n",
            "Epoch 231/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8739 - val_loss: 0.2655 - val_accuracy: 0.8756\n",
            "Epoch 232/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8765 - val_loss: 0.4485 - val_accuracy: 0.8458\n",
            "Epoch 233/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.8599 - val_loss: 0.3950 - val_accuracy: 0.8507\n",
            "Epoch 234/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8765 - val_loss: 0.4646 - val_accuracy: 0.8358\n",
            "Epoch 235/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.8504 - val_loss: 1.1461 - val_accuracy: 0.5124\n",
            "Epoch 236/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.9377 - accuracy: 0.6738 - val_loss: 0.6110 - val_accuracy: 0.7662\n",
            "Epoch 237/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.8143 - val_loss: 0.3655 - val_accuracy: 0.8706\n",
            "Epoch 238/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.8443 - val_loss: 0.3522 - val_accuracy: 0.8706\n",
            "Epoch 239/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.8090 - val_loss: 0.4243 - val_accuracy: 0.8557\n",
            "Epoch 240/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8699 - val_loss: 0.3639 - val_accuracy: 0.8706\n",
            "Epoch 241/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8782 - val_loss: 0.3775 - val_accuracy: 0.8507\n",
            "Epoch 242/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8686 - val_loss: 0.5983 - val_accuracy: 0.8209\n",
            "Epoch 243/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8908 - val_loss: 0.2851 - val_accuracy: 0.8905\n",
            "Epoch 244/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8508 - val_loss: 0.3488 - val_accuracy: 0.8856\n",
            "Epoch 245/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8926 - val_loss: 0.3837 - val_accuracy: 0.8806\n",
            "Epoch 246/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8765 - val_loss: 0.5955 - val_accuracy: 0.8408\n",
            "Epoch 247/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8834 - val_loss: 0.4825 - val_accuracy: 0.8308\n",
            "Epoch 248/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8647 - val_loss: 1.0571 - val_accuracy: 0.7164\n",
            "Epoch 249/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.7199 - accuracy: 0.7843 - val_loss: 0.6757 - val_accuracy: 0.8159\n",
            "Epoch 250/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.8391 - accuracy: 0.7742 - val_loss: 0.5951 - val_accuracy: 0.8308\n",
            "Epoch 251/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.8134 - val_loss: 0.3959 - val_accuracy: 0.8806\n",
            "Epoch 252/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8547 - val_loss: 0.3762 - val_accuracy: 0.8607\n",
            "Epoch 253/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.8617 - val_loss: 0.3186 - val_accuracy: 0.8856\n",
            "Epoch 254/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8804 - val_loss: 0.4267 - val_accuracy: 0.8806\n",
            "Epoch 255/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8747 - val_loss: 0.9422 - val_accuracy: 0.7463\n",
            "Epoch 256/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.8486 - val_loss: 0.4774 - val_accuracy: 0.8657\n",
            "Epoch 257/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8691 - val_loss: 0.6667 - val_accuracy: 0.8109\n",
            "Epoch 258/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8852 - val_loss: 0.3067 - val_accuracy: 0.8905\n",
            "Epoch 259/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.8991 - val_loss: 0.4267 - val_accuracy: 0.8507\n",
            "Epoch 260/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8952 - val_loss: 0.4514 - val_accuracy: 0.8458\n",
            "Epoch 261/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8686 - val_loss: 0.3465 - val_accuracy: 0.8607\n",
            "Epoch 262/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8782 - val_loss: 0.3386 - val_accuracy: 0.8706\n",
            "Epoch 263/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3144 - accuracy: 0.8856 - val_loss: 0.2869 - val_accuracy: 0.8856\n",
            "Epoch 264/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3254 - accuracy: 0.8878 - val_loss: 0.3677 - val_accuracy: 0.8657\n",
            "Epoch 265/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8904 - val_loss: 0.2683 - val_accuracy: 0.9055\n",
            "Epoch 266/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8873 - val_loss: 0.2863 - val_accuracy: 0.8905\n",
            "Epoch 267/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.8360 - val_loss: 0.4460 - val_accuracy: 0.8607\n",
            "Epoch 268/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2942 - accuracy: 0.8991 - val_loss: 0.3558 - val_accuracy: 0.8706\n",
            "Epoch 269/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8756 - val_loss: 0.3351 - val_accuracy: 0.8905\n",
            "Epoch 270/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8960 - val_loss: 0.3277 - val_accuracy: 0.8706\n",
            "Epoch 271/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2849 - accuracy: 0.8982 - val_loss: 0.3409 - val_accuracy: 0.8756\n",
            "Epoch 272/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8860 - val_loss: 0.3444 - val_accuracy: 0.8756\n",
            "Epoch 273/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8665 - val_loss: 0.6031 - val_accuracy: 0.8458\n",
            "Epoch 274/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8617 - val_loss: 0.3588 - val_accuracy: 0.8905\n",
            "Epoch 275/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8860 - val_loss: 0.3612 - val_accuracy: 0.8657\n",
            "Epoch 276/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3347 - accuracy: 0.8865 - val_loss: 0.3567 - val_accuracy: 0.8706\n",
            "Epoch 277/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4105 - accuracy: 0.8612 - val_loss: 0.5512 - val_accuracy: 0.8358\n",
            "Epoch 278/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8582 - val_loss: 0.4931 - val_accuracy: 0.8458\n",
            "Epoch 279/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3703 - accuracy: 0.8826 - val_loss: 0.4084 - val_accuracy: 0.8607\n",
            "Epoch 280/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3047 - accuracy: 0.9000 - val_loss: 0.3379 - val_accuracy: 0.8756\n",
            "Epoch 281/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8965 - val_loss: 0.3861 - val_accuracy: 0.8408\n",
            "Epoch 282/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8778 - val_loss: 0.6772 - val_accuracy: 0.8109\n",
            "Epoch 283/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8625 - val_loss: 0.4517 - val_accuracy: 0.8806\n",
            "Epoch 284/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3561 - accuracy: 0.8830 - val_loss: 0.2846 - val_accuracy: 0.8905\n",
            "Epoch 285/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8873 - val_loss: 0.3671 - val_accuracy: 0.8607\n",
            "Epoch 286/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8795 - val_loss: 0.3633 - val_accuracy: 0.8756\n",
            "Epoch 287/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8930 - val_loss: 0.4228 - val_accuracy: 0.8408\n",
            "Epoch 288/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8821 - val_loss: 0.3214 - val_accuracy: 0.8955\n",
            "Epoch 289/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.9000 - val_loss: 0.3231 - val_accuracy: 0.8706\n",
            "Epoch 290/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8517 - val_loss: 0.3885 - val_accuracy: 0.8458\n",
            "Epoch 291/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.8391 - val_loss: 0.3918 - val_accuracy: 0.8507\n",
            "Epoch 292/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8873 - val_loss: 0.3095 - val_accuracy: 0.8806\n",
            "Epoch 293/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2864 - accuracy: 0.8956 - val_loss: 0.4141 - val_accuracy: 0.8557\n",
            "Epoch 294/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8834 - val_loss: 0.3280 - val_accuracy: 0.8955\n",
            "Epoch 295/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.8995 - val_loss: 0.3642 - val_accuracy: 0.8706\n",
            "Epoch 296/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.8643 - val_loss: 0.5489 - val_accuracy: 0.7960\n",
            "Epoch 297/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8712 - val_loss: 0.3515 - val_accuracy: 0.8756\n",
            "Epoch 298/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2941 - accuracy: 0.8947 - val_loss: 0.3095 - val_accuracy: 0.8756\n",
            "Epoch 299/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.9039 - val_loss: 0.3329 - val_accuracy: 0.8806\n",
            "Epoch 300/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.8956 - val_loss: 0.4421 - val_accuracy: 0.8607\n",
            "Epoch 301/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8908 - val_loss: 0.9174 - val_accuracy: 0.7114\n",
            "Epoch 302/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.8573 - val_loss: 0.2752 - val_accuracy: 0.9005\n",
            "Epoch 303/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8882 - val_loss: 0.3686 - val_accuracy: 0.8657\n",
            "Epoch 304/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3471 - accuracy: 0.8821 - val_loss: 0.3609 - val_accuracy: 0.8458\n",
            "Epoch 305/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8856 - val_loss: 0.3465 - val_accuracy: 0.8657\n",
            "Epoch 306/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.8404 - val_loss: 0.5232 - val_accuracy: 0.8259\n",
            "Epoch 307/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3698 - accuracy: 0.8769 - val_loss: 0.3150 - val_accuracy: 0.8706\n",
            "Epoch 308/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.9108 - val_loss: 0.2791 - val_accuracy: 0.9055\n",
            "Epoch 309/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8856 - val_loss: 0.2481 - val_accuracy: 0.8856\n",
            "Epoch 310/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 0.8960 - val_loss: 0.3220 - val_accuracy: 0.8806\n",
            "Epoch 311/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.8965 - val_loss: 0.2786 - val_accuracy: 0.9005\n",
            "Epoch 312/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 0.9000 - val_loss: 0.3862 - val_accuracy: 0.8557\n",
            "Epoch 313/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8895 - val_loss: 0.4446 - val_accuracy: 0.8657\n",
            "Epoch 314/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3582 - accuracy: 0.8808 - val_loss: 0.4662 - val_accuracy: 0.8458\n",
            "Epoch 315/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8543 - val_loss: 0.5812 - val_accuracy: 0.7910\n",
            "Epoch 316/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8625 - val_loss: 0.2921 - val_accuracy: 0.8905\n",
            "Epoch 317/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8878 - val_loss: 0.4575 - val_accuracy: 0.8557\n",
            "Epoch 318/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2911 - accuracy: 0.8947 - val_loss: 0.4404 - val_accuracy: 0.8458\n",
            "Epoch 319/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.8952 - val_loss: 0.5506 - val_accuracy: 0.8060\n",
            "Epoch 320/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8769 - val_loss: 0.3496 - val_accuracy: 0.8557\n",
            "Epoch 321/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2925 - accuracy: 0.8969 - val_loss: 0.3562 - val_accuracy: 0.8706\n",
            "Epoch 322/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.8987 - val_loss: 0.2729 - val_accuracy: 0.9005\n",
            "Epoch 323/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.8904 - val_loss: 0.5492 - val_accuracy: 0.8109\n",
            "Epoch 324/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.8525 - val_loss: 0.8871 - val_accuracy: 0.6965\n",
            "Epoch 325/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8869 - val_loss: 0.4696 - val_accuracy: 0.8159\n",
            "Epoch 326/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.8956 - val_loss: 0.3469 - val_accuracy: 0.8756\n",
            "Epoch 327/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2830 - accuracy: 0.8991 - val_loss: 0.2925 - val_accuracy: 0.8856\n",
            "Epoch 328/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2679 - accuracy: 0.9021 - val_loss: 0.3024 - val_accuracy: 0.8706\n",
            "Epoch 329/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2657 - accuracy: 0.9034 - val_loss: 0.2742 - val_accuracy: 0.8756\n",
            "Epoch 330/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8904 - val_loss: 0.2927 - val_accuracy: 0.9005\n",
            "Epoch 331/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.8982 - val_loss: 0.2858 - val_accuracy: 0.8806\n",
            "Epoch 332/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.9013 - val_loss: 0.3593 - val_accuracy: 0.8706\n",
            "Epoch 333/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2741 - accuracy: 0.9056 - val_loss: 0.3138 - val_accuracy: 0.8905\n",
            "Epoch 334/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.9017 - val_loss: 0.3045 - val_accuracy: 0.8905\n",
            "Epoch 335/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2870 - accuracy: 0.8969 - val_loss: 0.2710 - val_accuracy: 0.8806\n",
            "Epoch 336/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2855 - accuracy: 0.9004 - val_loss: 0.3249 - val_accuracy: 0.8905\n",
            "Epoch 337/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2577 - accuracy: 0.9095 - val_loss: 0.4104 - val_accuracy: 0.8408\n",
            "Epoch 338/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8856 - val_loss: 0.2905 - val_accuracy: 0.8955\n",
            "Epoch 339/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8817 - val_loss: 0.3002 - val_accuracy: 0.8706\n",
            "Epoch 340/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8960 - val_loss: 0.2700 - val_accuracy: 0.8955\n",
            "Epoch 341/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8891 - val_loss: 0.2641 - val_accuracy: 0.8756\n",
            "Epoch 342/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8860 - val_loss: 0.3472 - val_accuracy: 0.8607\n",
            "Epoch 343/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8908 - val_loss: 0.3908 - val_accuracy: 0.8557\n",
            "Epoch 344/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8917 - val_loss: 0.3696 - val_accuracy: 0.8756\n",
            "Epoch 345/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8947 - val_loss: 0.3135 - val_accuracy: 0.8756\n",
            "Epoch 346/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8965 - val_loss: 0.3081 - val_accuracy: 0.8856\n",
            "Epoch 347/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8943 - val_loss: 0.4737 - val_accuracy: 0.8358\n",
            "Epoch 348/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8791 - val_loss: 0.3003 - val_accuracy: 0.8955\n",
            "Epoch 349/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8895 - val_loss: 0.4910 - val_accuracy: 0.8308\n",
            "Epoch 350/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.9030 - val_loss: 0.2493 - val_accuracy: 0.8955\n",
            "Epoch 351/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.9126 - val_loss: 0.2624 - val_accuracy: 0.8756\n",
            "Epoch 352/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2818 - accuracy: 0.9013 - val_loss: 0.3485 - val_accuracy: 0.8706\n",
            "Epoch 353/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.9026 - val_loss: 0.2660 - val_accuracy: 0.8856\n",
            "Epoch 354/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.8995 - val_loss: 0.4103 - val_accuracy: 0.8507\n",
            "Epoch 355/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8934 - val_loss: 0.3304 - val_accuracy: 0.8905\n",
            "Epoch 356/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8878 - val_loss: 0.3343 - val_accuracy: 0.8806\n",
            "Epoch 357/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2711 - accuracy: 0.9047 - val_loss: 0.4303 - val_accuracy: 0.8458\n",
            "Epoch 358/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8773 - val_loss: 0.4043 - val_accuracy: 0.8657\n",
            "Epoch 359/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8939 - val_loss: 0.3094 - val_accuracy: 0.8806\n",
            "Epoch 360/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.9047 - val_loss: 0.3301 - val_accuracy: 0.8657\n",
            "Epoch 361/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2717 - accuracy: 0.9047 - val_loss: 0.3649 - val_accuracy: 0.8358\n",
            "Epoch 362/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2556 - accuracy: 0.9087 - val_loss: 0.2560 - val_accuracy: 0.8955\n",
            "Epoch 363/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.9143 - val_loss: 0.3339 - val_accuracy: 0.8607\n",
            "Epoch 364/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8678 - val_loss: 0.4077 - val_accuracy: 0.8507\n",
            "Epoch 365/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.8978 - val_loss: 0.2589 - val_accuracy: 0.8806\n",
            "Epoch 366/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2649 - accuracy: 0.9017 - val_loss: 0.2495 - val_accuracy: 0.8955\n",
            "Epoch 367/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2524 - accuracy: 0.9113 - val_loss: 0.3138 - val_accuracy: 0.8756\n",
            "Epoch 368/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9100 - val_loss: 0.2525 - val_accuracy: 0.8756\n",
            "Epoch 369/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.9008 - val_loss: 0.5835 - val_accuracy: 0.8060\n",
            "Epoch 370/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8617 - val_loss: 0.5599 - val_accuracy: 0.7811\n",
            "Epoch 371/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8895 - val_loss: 0.3223 - val_accuracy: 0.8806\n",
            "Epoch 372/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8921 - val_loss: 0.3567 - val_accuracy: 0.8607\n",
            "Epoch 373/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.8995 - val_loss: 0.2668 - val_accuracy: 0.8856\n",
            "Epoch 374/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.9117 - val_loss: 0.2492 - val_accuracy: 0.8905\n",
            "Epoch 375/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2398 - accuracy: 0.9156 - val_loss: 0.2557 - val_accuracy: 0.8955\n",
            "Epoch 376/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.9208 - val_loss: 0.3190 - val_accuracy: 0.8756\n",
            "Epoch 377/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8952 - val_loss: 0.2738 - val_accuracy: 0.8905\n",
            "Epoch 378/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3491 - accuracy: 0.8843 - val_loss: 0.2989 - val_accuracy: 0.8657\n",
            "Epoch 379/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.9100 - val_loss: 0.2627 - val_accuracy: 0.8706\n",
            "Epoch 380/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.9095 - val_loss: 0.3158 - val_accuracy: 0.8557\n",
            "Epoch 381/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9134 - val_loss: 0.4212 - val_accuracy: 0.8607\n",
            "Epoch 382/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8834 - val_loss: 0.2664 - val_accuracy: 0.8955\n",
            "Epoch 383/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2482 - accuracy: 0.9117 - val_loss: 0.2314 - val_accuracy: 0.8856\n",
            "Epoch 384/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2725 - accuracy: 0.9030 - val_loss: 0.2659 - val_accuracy: 0.8856\n",
            "Epoch 385/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2738 - accuracy: 0.9034 - val_loss: 0.3348 - val_accuracy: 0.8657\n",
            "Epoch 386/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3138 - accuracy: 0.9008 - val_loss: 0.2768 - val_accuracy: 0.8856\n",
            "Epoch 387/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2915 - accuracy: 0.8987 - val_loss: 0.2443 - val_accuracy: 0.8856\n",
            "Epoch 388/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.9060 - val_loss: 0.3435 - val_accuracy: 0.8607\n",
            "Epoch 389/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.8926 - val_loss: 0.2480 - val_accuracy: 0.8856\n",
            "Epoch 390/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.9169 - val_loss: 0.2635 - val_accuracy: 0.8955\n",
            "Epoch 391/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.9074 - val_loss: 0.3198 - val_accuracy: 0.8607\n",
            "Epoch 392/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2824 - accuracy: 0.9004 - val_loss: 0.2696 - val_accuracy: 0.8806\n",
            "Epoch 393/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.9087 - val_loss: 0.2444 - val_accuracy: 0.8806\n",
            "Epoch 394/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.9060 - val_loss: 0.3009 - val_accuracy: 0.8905\n",
            "Epoch 395/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.9095 - val_loss: 0.3362 - val_accuracy: 0.8458\n",
            "Epoch 396/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2576 - accuracy: 0.9082 - val_loss: 0.2570 - val_accuracy: 0.9005\n",
            "Epoch 397/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2769 - accuracy: 0.8978 - val_loss: 0.2347 - val_accuracy: 0.8955\n",
            "Epoch 398/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.9069 - val_loss: 0.2508 - val_accuracy: 0.8905\n",
            "Epoch 399/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.9047 - val_loss: 0.2897 - val_accuracy: 0.8756\n",
            "Epoch 400/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2428 - accuracy: 0.9156 - val_loss: 0.2702 - val_accuracy: 0.8955\n",
            "Epoch 401/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.9052 - val_loss: 0.2641 - val_accuracy: 0.9005\n",
            "Epoch 402/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2616 - accuracy: 0.9095 - val_loss: 0.2715 - val_accuracy: 0.8856\n",
            "Epoch 403/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2586 - accuracy: 0.9013 - val_loss: 0.3459 - val_accuracy: 0.8458\n",
            "Epoch 404/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.9056 - val_loss: 0.3324 - val_accuracy: 0.8657\n",
            "Epoch 405/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2899 - accuracy: 0.9026 - val_loss: 0.2467 - val_accuracy: 0.8955\n",
            "Epoch 406/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8969 - val_loss: 0.3052 - val_accuracy: 0.8756\n",
            "Epoch 407/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8869 - val_loss: 0.3430 - val_accuracy: 0.8806\n",
            "Epoch 408/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.9095 - val_loss: 0.3002 - val_accuracy: 0.8905\n",
            "Epoch 409/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9121 - val_loss: 0.3286 - val_accuracy: 0.8806\n",
            "Epoch 410/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.9117 - val_loss: 0.3399 - val_accuracy: 0.8706\n",
            "Epoch 411/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2694 - accuracy: 0.9060 - val_loss: 0.4248 - val_accuracy: 0.8607\n",
            "Epoch 412/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.9047 - val_loss: 0.2600 - val_accuracy: 0.9055\n",
            "Epoch 413/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.9034 - val_loss: 0.2942 - val_accuracy: 0.8856\n",
            "Epoch 414/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.9095 - val_loss: 0.2372 - val_accuracy: 0.9254\n",
            "Epoch 415/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2306 - accuracy: 0.9182 - val_loss: 0.2693 - val_accuracy: 0.8905\n",
            "Epoch 416/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.9047 - val_loss: 0.2757 - val_accuracy: 0.8905\n",
            "Epoch 417/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.9182 - val_loss: 0.3193 - val_accuracy: 0.8806\n",
            "Epoch 418/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.9039 - val_loss: 0.3453 - val_accuracy: 0.8607\n",
            "Epoch 419/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.9100 - val_loss: 0.2344 - val_accuracy: 0.8905\n",
            "Epoch 420/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.9095 - val_loss: 0.2633 - val_accuracy: 0.8756\n",
            "Epoch 421/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2676 - accuracy: 0.9078 - val_loss: 0.2615 - val_accuracy: 0.8905\n",
            "Epoch 422/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.9087 - val_loss: 0.2400 - val_accuracy: 0.8856\n",
            "Epoch 423/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2841 - accuracy: 0.8978 - val_loss: 0.2442 - val_accuracy: 0.9154\n",
            "Epoch 424/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.9156 - val_loss: 0.2724 - val_accuracy: 0.9005\n",
            "Epoch 425/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.9113 - val_loss: 0.2850 - val_accuracy: 0.9005\n",
            "Epoch 426/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.9087 - val_loss: 0.3021 - val_accuracy: 0.8806\n",
            "Epoch 427/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.9030 - val_loss: 0.2249 - val_accuracy: 0.8905\n",
            "Epoch 428/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2713 - accuracy: 0.9087 - val_loss: 0.2652 - val_accuracy: 0.8706\n",
            "Epoch 429/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9100 - val_loss: 0.3242 - val_accuracy: 0.8756\n",
            "Epoch 430/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.9121 - val_loss: 0.2489 - val_accuracy: 0.9055\n",
            "Epoch 431/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.9021 - val_loss: 0.2472 - val_accuracy: 0.9055\n",
            "Epoch 432/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2600 - accuracy: 0.9108 - val_loss: 0.2628 - val_accuracy: 0.8905\n",
            "Epoch 433/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9208 - val_loss: 0.2831 - val_accuracy: 0.8806\n",
            "Epoch 434/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9147 - val_loss: 0.2795 - val_accuracy: 0.8806\n",
            "Epoch 435/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2695 - accuracy: 0.9056 - val_loss: 0.2447 - val_accuracy: 0.8856\n",
            "Epoch 436/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.9139 - val_loss: 0.3924 - val_accuracy: 0.8607\n",
            "Epoch 437/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2582 - accuracy: 0.9017 - val_loss: 0.2351 - val_accuracy: 0.8955\n",
            "Epoch 438/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.9026 - val_loss: 0.3888 - val_accuracy: 0.8458\n",
            "Epoch 439/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8852 - val_loss: 0.2612 - val_accuracy: 0.8806\n",
            "Epoch 440/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2887 - accuracy: 0.8987 - val_loss: 0.2636 - val_accuracy: 0.8955\n",
            "Epoch 441/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2875 - accuracy: 0.8934 - val_loss: 0.2425 - val_accuracy: 0.8756\n",
            "Epoch 442/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.9013 - val_loss: 0.2806 - val_accuracy: 0.8905\n",
            "Epoch 443/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.9113 - val_loss: 0.2236 - val_accuracy: 0.9055\n",
            "Epoch 444/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.9047 - val_loss: 0.2670 - val_accuracy: 0.8706\n",
            "Epoch 445/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.9082 - val_loss: 0.2406 - val_accuracy: 0.8905\n",
            "Epoch 446/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.9095 - val_loss: 0.3610 - val_accuracy: 0.8706\n",
            "Epoch 447/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.8969 - val_loss: 0.2891 - val_accuracy: 0.8657\n",
            "Epoch 448/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.9026 - val_loss: 0.2198 - val_accuracy: 0.9055\n",
            "Epoch 449/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.9069 - val_loss: 0.3938 - val_accuracy: 0.8607\n",
            "Epoch 450/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2630 - accuracy: 0.9113 - val_loss: 0.3444 - val_accuracy: 0.8706\n",
            "Epoch 451/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8869 - val_loss: 0.3551 - val_accuracy: 0.8657\n",
            "Epoch 452/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8956 - val_loss: 0.3540 - val_accuracy: 0.8657\n",
            "Epoch 453/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2389 - accuracy: 0.9143 - val_loss: 0.2521 - val_accuracy: 0.8806\n",
            "Epoch 454/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9161 - val_loss: 0.2495 - val_accuracy: 0.8955\n",
            "Epoch 455/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2268 - accuracy: 0.9134 - val_loss: 0.2323 - val_accuracy: 0.9005\n",
            "Epoch 456/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.9074 - val_loss: 0.2634 - val_accuracy: 0.8756\n",
            "Epoch 457/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.9065 - val_loss: 0.2631 - val_accuracy: 0.8905\n",
            "Epoch 458/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9117 - val_loss: 0.2629 - val_accuracy: 0.8955\n",
            "Epoch 459/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.9113 - val_loss: 0.2403 - val_accuracy: 0.8905\n",
            "Epoch 460/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.9100 - val_loss: 0.2503 - val_accuracy: 0.8706\n",
            "Epoch 461/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.9052 - val_loss: 0.2619 - val_accuracy: 0.9005\n",
            "Epoch 462/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.9100 - val_loss: 0.2529 - val_accuracy: 0.8806\n",
            "Epoch 463/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9113 - val_loss: 0.2563 - val_accuracy: 0.8955\n",
            "Epoch 464/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8960 - val_loss: 0.3591 - val_accuracy: 0.8706\n",
            "Epoch 465/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.9043 - val_loss: 0.2811 - val_accuracy: 0.8856\n",
            "Epoch 466/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.9060 - val_loss: 0.2737 - val_accuracy: 0.8955\n",
            "Epoch 467/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2315 - accuracy: 0.9187 - val_loss: 0.3023 - val_accuracy: 0.8955\n",
            "Epoch 468/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.9052 - val_loss: 0.3109 - val_accuracy: 0.8706\n",
            "Epoch 469/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8917 - val_loss: 0.4164 - val_accuracy: 0.8607\n",
            "Epoch 470/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.9113 - val_loss: 0.2512 - val_accuracy: 0.8856\n",
            "Epoch 471/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.9065 - val_loss: 0.2853 - val_accuracy: 0.8806\n",
            "Epoch 472/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.9126 - val_loss: 0.2814 - val_accuracy: 0.8806\n",
            "Epoch 473/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8869 - val_loss: 0.3030 - val_accuracy: 0.8756\n",
            "Epoch 474/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.9121 - val_loss: 0.3539 - val_accuracy: 0.8856\n",
            "Epoch 475/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.9134 - val_loss: 0.2697 - val_accuracy: 0.8955\n",
            "Epoch 476/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9182 - val_loss: 0.3747 - val_accuracy: 0.8706\n",
            "Epoch 477/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.8952 - val_loss: 0.4929 - val_accuracy: 0.8159\n",
            "Epoch 478/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2878 - accuracy: 0.8987 - val_loss: 0.3221 - val_accuracy: 0.8557\n",
            "Epoch 479/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.9126 - val_loss: 0.2229 - val_accuracy: 0.8905\n",
            "Epoch 480/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.9095 - val_loss: 0.3209 - val_accuracy: 0.8955\n",
            "Epoch 481/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2420 - accuracy: 0.9056 - val_loss: 0.3386 - val_accuracy: 0.8856\n",
            "Epoch 482/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2344 - accuracy: 0.9156 - val_loss: 0.2540 - val_accuracy: 0.8856\n",
            "Epoch 483/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.9069 - val_loss: 0.2402 - val_accuracy: 0.9005\n",
            "Epoch 484/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.9174 - val_loss: 0.2291 - val_accuracy: 0.9005\n",
            "Epoch 485/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2550 - accuracy: 0.9139 - val_loss: 0.2461 - val_accuracy: 0.8955\n",
            "Epoch 486/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9187 - val_loss: 0.2373 - val_accuracy: 0.9055\n",
            "Epoch 487/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2505 - accuracy: 0.9078 - val_loss: 0.2319 - val_accuracy: 0.8756\n",
            "Epoch 488/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9161 - val_loss: 0.2525 - val_accuracy: 0.8856\n",
            "Epoch 489/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9221 - val_loss: 0.2766 - val_accuracy: 0.8756\n",
            "Epoch 490/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.9082 - val_loss: 0.2837 - val_accuracy: 0.8806\n",
            "Epoch 491/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9187 - val_loss: 0.2589 - val_accuracy: 0.8856\n",
            "Epoch 492/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2413 - accuracy: 0.9139 - val_loss: 0.2693 - val_accuracy: 0.8905\n",
            "Epoch 493/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.9130 - val_loss: 0.2365 - val_accuracy: 0.9055\n",
            "Epoch 494/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2575 - accuracy: 0.9052 - val_loss: 0.3408 - val_accuracy: 0.8657\n",
            "Epoch 495/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.9082 - val_loss: 0.2465 - val_accuracy: 0.8905\n",
            "Epoch 496/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.9060 - val_loss: 0.2242 - val_accuracy: 0.8856\n",
            "Epoch 497/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2348 - accuracy: 0.9156 - val_loss: 0.2548 - val_accuracy: 0.8856\n",
            "Epoch 498/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.9126 - val_loss: 0.2799 - val_accuracy: 0.8607\n",
            "Epoch 499/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.3191 - accuracy: 0.8921 - val_loss: 0.3740 - val_accuracy: 0.8607\n",
            "Epoch 500/500\n",
            "72/72 [==============================] - 0s 2ms/step - loss: 0.2525 - accuracy: 0.9104 - val_loss: 0.2369 - val_accuracy: 0.8905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model analysis\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sULcVIwxeCwV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "deb293c9-7472-4206-dc1e-d2cf740f841b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Save the model as keras model file\n",
        "model.save('bean_classification_update3.h5')\n",
        "files.download('bean_classification_update3.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "m50rAv470fao",
        "outputId": "64c206cf-2943-4951-8d54-0d130c356731"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ef7f7d4e-41e4-4562-a98b-2f44125943e5\", \"bean_classification_update3.h5\", 158048)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}